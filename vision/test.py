import torch
import pyrealsense2 as rs
import numpy as np
import cv2
from ultralytics import YOLO

device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
model = YOLO("yolov8m.pt").to(device)
conf_threshold=0.5
infer_param = {
    'conf': conf_threshold,
    'device': device,
    'dnn': False
}
#from scipy.spatial.distance import cdist
# 1. é…ç½®ç®¡é“
pipe = rs.pipeline()
cfg = rs.config()

# âš ï¸ å¿…é¡»å¼€å¯æ·±åº¦æµæ‰èƒ½è®¡ç®—ç‚¹äº‘
# D455 æ¨èåˆ†è¾¨ç‡: 848x480 æˆ– 640x480
cfg.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
cfg.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)

# 2. åˆ›å»ºç‚¹äº‘å¤„ç†å¯¹è±¡
pc = rs.pointcloud()

# 3. åˆ›å»ºå¯¹é½å¯¹è±¡ (å°†æ·±åº¦å¯¹é½åˆ°å½©è‰²ï¼Œä¸ºäº†ç”Ÿæˆå½©è‰²ç‚¹äº‘)
align_to = rs.stream.color
align = rs.align(align_to)
# â­ï¸ æ–°å¢ï¼šåˆ›å»ºé¢œè‰²æ˜ å°„å™¨ (ç”¨äºå°†æ·±åº¦å€¼è½¬ä¸ºå½©è‰²å›¾åƒ)
colorizer = rs.colorizer()
try:
    print("â³ æ­£åœ¨å¯åŠ¨ç›¸æœº...")
    pipe.start(cfg)
    print("âœ… ç›¸æœºå·²å¯åŠ¨ï¼ŒæŒ‰ 'q' é€€å‡ºï¼ŒæŒ‰ 's' ä¿å­˜ç‚¹äº‘æ–‡ä»¶")

    while True:
        # ç­‰å¾…å¸§
        frames = pipe.wait_for_frames()
        # 4. å¯¹é½å¸§ (å…³é”®æ­¥éª¤ï¼šè®©æ·±åº¦å›¾çš„åƒç´ å’Œå½©è‰²å›¾çš„åƒç´ åæ ‡å¯¹åº”)
        aligned_frames = align.process(frames)

        # è·å–å¯¹é½åçš„æ·±åº¦å¸§å’Œå½©è‰²å¸§
        aligned_depth_frame = aligned_frames.get_depth_frame()
        color_frame = aligned_frames.get_color_frame()
        
        # éªŒè¯æ˜¯å¦ä¸¤å¸§éƒ½æœ‰
        if not aligned_depth_frame or not color_frame:
            continue
        # â­ï¸ æ–°å¢ï¼šåº”ç”¨é¢œè‰²æ˜ å°„å™¨åˆ°å¯¹é½åçš„æ·±åº¦å¸§
        colorized_depth = colorizer.process(aligned_depth_frame)
        
        # --- æ ¸å¿ƒï¼šç”Ÿæˆç‚¹äº‘ ---
        
        # A. å‘Šè¯‰ç‚¹äº‘å¯¹è±¡ï¼Œæˆ‘ä»¬è¦ç”¨è¿™ä¸€å¸§å½©è‰²å›¾åƒä½œä¸ºçº¹ç†
        pc.map_to(color_frame)

        # B. è®¡ç®—ç‚¹äº‘ (ç”Ÿæˆ 3D åæ ‡)
        points = pc.calculate(aligned_depth_frame)

        # --- æ•°æ®è½¬æ¢ (è½¬ä¸º Numpyä»¥ä¾¿å¤„ç†) ---
        
        # è·å–é¡¶ç‚¹åæ ‡ (x, y, z)
        # åŸå§‹æ•°æ®æ˜¯ç»“æ„åŒ–æ•°ç»„ï¼Œæˆ‘ä»¬éœ€è¦å°†å…¶è½¬æ¢ä¸ºæ ‡å‡†çš„ (N, 3) float32 æ•°ç»„
        vtx = np.asanyarray(points.get_vertices())
        # view è½¬æ¢æ˜¯å°†å†…å­˜é‡æ–°è§£é‡Šï¼Œreshape å˜æˆ Nè¡Œ3åˆ—
        vertices = vtx.view(np.float32).reshape(-1, 3)

        # è·å–çº¹ç†åæ ‡ (u, v) - å¦‚æœä½ éœ€è¦çº¹ç†æ˜ å°„
        tex = np.asanyarray(points.get_texture_coordinates())
        # texture_coords = tex.view(np.float32).reshape(-1, 2)

        # --- å¯è§†åŒ– (æ˜¾ç¤ºå½©è‰²å›¾ä½œä¸ºå‚è€ƒ) ---
        color_image = np.asanyarray(color_frame.get_data())
  
        # 0,0==============>640
        # ||
        # ||
        # \/
        # 480
        # print(color_image.shape)
        # ç»“æœä¸º(480,640,3)
        # â­ï¸ æ·±åº¦å›¾ç°åœ¨ä¹Ÿæ˜¯ BGR æ ¼å¼çš„ 8 ä½å›¾åƒï¼Œå¯ä»¥ç›´æ¥ç”¨äº imshow
        depth_colormap = np.asanyarray(colorized_depth.get_data())
        # print( (np.asanyarray(aligned_depth_frame.get_data())).shape)
        # åœ¨å›¾åƒä¸Šæ‰“å°å½“å‰ç‚¹äº‘ç‚¹çš„æ•°é‡
        # cv2.putText(color_image, f"Points: {len(vertices)}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        # æ‹¼æ¥æ˜¾ç¤º(å½©è‰²å›¾åœ¨å·¦ï¼Œå½©è‰²æ·±åº¦å›¾åœ¨å³)
        # images = np.hstack((color_image, color_image))
        # åœ¨å›¾åƒä¸Šæ‰“å°ä¿¡æ¯ (å¯é€‰)
        # cv2.putText(images, "Color | Depth", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        
        # è¿™é‡Œresultsæ˜¯é•¿åº¦ä¸º1çš„listï¼Œprint(len(results))å¯çŸ¥
        results = model(color_image, **infer_param)
        box_info_list = []
        new_image = color_image.copy()
        if results[0].boxes is not None:
            print(f"å½“å‰æ£€æµ‹ç›®æ ‡æ•°ï¼š{len(results[0].boxes)}")
            class_names = results[0].names
            for box in results[0].boxes:
                [x1,y1,x2,y2] = box.xyxy.cpu().numpy().tolist()[0]
                print([x1,y1,x2,y2])
                print(box.cls.cpu().numpy()[0])
                class_idx = int(box.cls.cpu().numpy()[0])
                class_name = class_names[class_idx]
                cv2.rectangle(new_image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)
                cv2.putText(new_image, class_name, (int(x1), int(y1-10)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
                    
        cv2.imshow("RealSense Color (Aligned)", new_image)
        
        key = cv2.waitKey(1)
        
        # æŒ‰ 'q' é€€å‡º
        if key == ord('q'):
            break
        
        # æŒ‰ 's' ä¿å­˜ä¸º .ply æ–‡ä»¶ (å¯ä»¥ç”¨ MeshLab æˆ– CloudCompare æ‰“å¼€)
        if key == ord('s'):
            print("ğŸ’¾ æ­£åœ¨ä¿å­˜ pointcloud.ply ...")
            points.export_to_ply("pointcloud.ply", color_frame)
            print("âœ… ä¿å­˜æˆåŠŸï¼")

finally:
    pipe.stop()
    cv2.destroyAllWindows()
